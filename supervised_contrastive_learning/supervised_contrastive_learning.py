# -*- coding: utf-8 -*-
"""supervised-contrastive-learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ouFUA38P7VXIvnQMv1GmI0LsxEXXmN_I
"""
from data.data_tf import sample_generator, map_class_labels, normalize_image

import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow import keras
from tensorflow.keras import layers

""" Constants and Hyperparameters """
input_shape = [128, 128, 3]
learning_rate = 0.001
batch_size = 16
hidden_units = 512
projection_units = 128
num_epochs = 50
dropout_rate = 0.5
temperature = 0.05
num_classes = 21

""" Data Preparation Section"""
# Load the train and test data splits
train_ds = tf.data.Dataset.from_generator(
    sample_generator(split='train'),
    (tf.int32, tf.int32, tf.string),
    (input_shape, input_shape, [])
)

val_ds = tf.data.Dataset.from_generator(
    sample_generator(split='val'),
    (tf.int32, tf.int32, tf.string),
    (input_shape, input_shape, [])
)

test_ds = tf.data.Dataset.from_generator(
    sample_generator(split='test'),
    (tf.int32, tf.int32, tf.string),
    (input_shape, input_shape, [])
)

train_ds = train_ds.map(map_class_labels)
train_ds = train_ds.map(normalize_image)
train_ds = train_ds.batch(batch_size=batch_size)

val_ds = val_ds.map(map_class_labels)
val_ds = val_ds.map(normalize_image)
val_ds = val_ds.batch(batch_size=batch_size)

test_ds = test_ds.map(map_class_labels)
test_ds = test_ds.map(normalize_image)
test_ds = test_ds.batch(batch_size=batch_size)

"""# Data Augmentation"""

data_augmentation = keras.Sequential(
    [
        layers.experimental.preprocessing.Normalization(),
        layers.experimental.preprocessing.RandomFlip("horizontal"),
        layers.experimental.preprocessing.RandomRotation(0.02),
        layers.experimental.preprocessing.RandomWidth(0.2),
        layers.experimental.preprocessing.RandomHeight(0.2),
    ]
)

"""# Build the encoder model"""
def create_encoder():
    resnet = keras.applications.ResNet50V2(
        include_top=False, weights=None, input_shape=tuple(input_shape), pooling="avg"
    )

    inputs = keras.Input(shape=tuple(input_shape))
    augmented = data_augmentation(inputs)
    outputs = resnet(augmented)
    model = keras.Model(inputs=inputs, outputs=outputs, name="simplenet-encoder")
    return model


encoder = create_encoder()
print(encoder.summary())


"""# Build the classification model"""
def create_classifier(encoder, trainable=False):

    for layer in encoder.layers:
        layer.trainable = trainable

    inputs = keras.Input(shape=tuple(input_shape))
    features = encoder(inputs)
    features = layers.Dropout(dropout_rate)(features)
    features = layers.Dense(hidden_units, activation="relu")(features)
    features = layers.Dropout(dropout_rate)(features)
    outputs = layers.Dense(num_classes, activation="softmax")(features)

    model = keras.Model(inputs=inputs, outputs=outputs, name="cifar10-classifier")
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate),
        loss=keras.losses.SparseCategoricalCrossentropy(),
        metrics=[keras.metrics.SparseCategoricalAccuracy()],
    )
    return model

"""# Supervised contrastive learning loss function"""
class SupervisedContrastiveLoss(keras.losses.Loss):
    def __init__(self, temperature=1, name=None):
        super(SupervisedContrastiveLoss, self).__init__(name=name)
        self.temperature = temperature

    def __call__(self, labels, feature_vectors, sample_weight=None):
        # Normalize feature vectors
        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)
        # Compute logits
        logits = tf.divide(
            tf.matmul(
                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)
            ),
            self.temperature,
        )
        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)


def add_projection_head(encoder):
    inputs = keras.Input(shape=tuple(input_shape))
    features = encoder(inputs)
    outputs = layers.Dense(projection_units, activation="relu")(features)
    model = keras.Model(
        inputs=inputs, outputs=outputs, name="simplenet-encoder_with_projection-head"
    )
    return model

"""# Pretrain the encoder"""
encoder = create_encoder()

encoder_with_projection_head = add_projection_head(encoder)
encoder_with_projection_head.compile(
    optimizer=keras.optimizers.Adam(learning_rate),
    loss=SupervisedContrastiveLoss(temperature),
)

print(encoder_with_projection_head.summary())

history = encoder_with_projection_head.fit(
    x=train_ds, y=y_train, batch_size=batch_size, epochs=num_epochs
)

"""# Train the classifier with the frozen encoder"""

classifier = create_classifier(encoder, trainable=False)

history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)

accuracy = classifier.evaluate(x_test, y_test)[1]
print(f"Test accuracy: {round(accuracy * 100, 2)}%")