{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self-supervised-representation-learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS40bawtY-7N"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQp-LygaUez"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AYNI3wMaYHk"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7Yyc5slaW20"
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_data = np.concatenate([x_train, x_test])\n",
        "y_data = np.concatenate([y_train, y_test])\n",
        "\n",
        "print(\"x_data shape:\", x_data.shape, \"- y_data shape:\", y_data.shape)\n",
        "\n",
        "classes = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFAKV___ad03"
      },
      "source": [
        "# Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbPBVfVRag7n"
      },
      "source": [
        "target_size = 32  # Resize the input images.\n",
        "representation_dim = 512  # The dimensions of the features vector.\n",
        "projection_units = 128  # The projection head of the representation learner."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Ct2KwIaoK3"
      },
      "source": [
        "# Implement data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI87_O2Hal5M"
      },
      "source": [
        "data_preprocessing = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.Resizing(target_size, target_size),\n",
        "        layers.experimental.preprocessing.Normalization(),\n",
        "    ]\n",
        ")\n",
        "# Compute the mean and the variance from the data for normalization.\n",
        "data_preprocessing.layers[-1].adapt(x_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNO8ExDOatkv"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKnN4wnharTJ"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomTranslation(\n",
        "            height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), fill_mode=\"nearest\"\n",
        "        ),\n",
        "        layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(\n",
        "            factor=0.15, fill_mode=\"nearest\"\n",
        "        ),\n",
        "        layers.experimental.preprocessing.RandomZoom(\n",
        "            height_factor=(-0.3, 0.1), width_factor=(-0.3, 0.1), fill_mode=\"nearest\"\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzcMa9hka4um"
      },
      "source": [
        "# Self-supervised representation learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Ioa34Ya12v"
      },
      "source": [
        "def create_encoder(representation_dim):\n",
        "    encoder = keras.Sequential(\n",
        "        [\n",
        "            keras.applications.ResNet50V2(\n",
        "                include_top=False, weights=None, pooling=\"avg\"\n",
        "            ),\n",
        "            layers.Dense(representation_dim),\n",
        "        ]\n",
        "    )\n",
        "    return encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z7f5dGNa_x_"
      },
      "source": [
        "# Unsupervised contrastive loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCqlgujba8tN"
      },
      "source": [
        "class RepresentationLearner(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder,\n",
        "        projection_units,\n",
        "        num_augmentations,\n",
        "        temperature=1.0,\n",
        "        dropout_rate=0.1,\n",
        "        l2_normalize=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(RepresentationLearner, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        # Create projection head.\n",
        "        self.projector = keras.Sequential(\n",
        "            [\n",
        "                layers.Dropout(dropout_rate),\n",
        "                layers.Dense(units=projection_units, use_bias=False),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.ReLU(),\n",
        "            ]\n",
        "        )\n",
        "        self.num_augmentations = num_augmentations\n",
        "        self.temperature = temperature\n",
        "        self.l2_normalize = l2_normalize\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def compute_contrastive_loss(self, feature_vectors, batch_size):\n",
        "        num_augmentations = tf.shape(feature_vectors)[0] // batch_size\n",
        "        if self.l2_normalize:\n",
        "            feature_vectors = tf.math.l2_normalize(feature_vectors, -1)\n",
        "        # The logits shape is [num_augmentations * batch_size, num_augmentations * batch_size].\n",
        "        logits = (\n",
        "            tf.linalg.matmul(feature_vectors, feature_vectors, transpose_b=True)\n",
        "            / self.temperature\n",
        "        )\n",
        "        # Apply log-max trick for numerical stability.\n",
        "        logits_max = tf.math.reduce_max(logits, axis=1)\n",
        "        logits = logits - logits_max\n",
        "        # The shape of targets is [num_augmentations * batch_size, num_augmentations * batch_size].\n",
        "        # targets is a matrix consits of num_augmentations submatrices of shape [batch_size * batch_size].\n",
        "        # Each [batch_size * batch_size] submatrix is an identity matrix (diagonal entries are ones).\n",
        "        targets = tf.tile(tf.eye(batch_size), [num_augmentations, num_augmentations])\n",
        "        # Compute cross entropy loss\n",
        "        return keras.losses.categorical_crossentropy(\n",
        "            y_true=targets, y_pred=logits, from_logits=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Preprocess the input images.\n",
        "        preprocessed = data_preprocessing(inputs)\n",
        "        # Create augmented versions of the images.\n",
        "        augmented = []\n",
        "        for _ in range(self.num_augmentations):\n",
        "            augmented.append(data_augmentation(preprocessed))\n",
        "        augmented = layers.Concatenate(axis=0)(augmented)\n",
        "        # Generate embedding representations of the images.\n",
        "        features = self.encoder(augmented)\n",
        "        # Apply projection head.\n",
        "        return self.projector(features)\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        # Run the forward pass and compute the contrastive loss\n",
        "        with tf.GradientTape() as tape:\n",
        "            feature_vectors = self(inputs, training=True)\n",
        "            loss = self.compute_contrastive_loss(feature_vectors, batch_size)\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update loss tracker metric\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        feature_vectors = self(inputs, training=False)\n",
        "        loss = self.compute_contrastive_loss(feature_vectors, batch_size)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPOOuWj2bIYk"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ3b4-jmbGuj"
      },
      "source": [
        "# Create vision encoder.\n",
        "encoder = create_encoder(representation_dim)\n",
        "# Create representation learner.\n",
        "representation_learner = RepresentationLearner(\n",
        "    encoder, projection_units, num_augmentations=2, temperature=0.1\n",
        ")\n",
        "# Create a a Cosine decay learning rate scheduler.\n",
        "lr_scheduler = keras.experimental.CosineDecay(\n",
        "    initial_learning_rate=0.001, decay_steps=500, alpha=0.1\n",
        ")\n",
        "# Compile the model.\n",
        "representation_learner.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(learning_rate=lr_scheduler, weight_decay=0.0001),\n",
        ")\n",
        "# Fit the model.\n",
        "history = representation_learner.fit(\n",
        "    x=x_data,\n",
        "    batch_size=512,\n",
        "    epochs=50,  # for better results, increase the number of epochs to 500.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X48cbnuLbPGH"
      },
      "source": [
        "# Plot training loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWwauWZJbOvi"
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}